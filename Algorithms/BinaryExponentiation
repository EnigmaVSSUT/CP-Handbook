Algorithm

Raising a
to the power of n is expressed naively as multiplication by a done n−1 times: an=a⋅a⋅…⋅a. However, this approach is not practical for large a or n

.

ab+c=ab⋅ac
and a2b=ab⋅ab=(ab)2

.

The idea of binary exponentiation is, that we split the work using the binary representation of the exponent.

Let's write n

in base 2, for example:
313=311012=38⋅34⋅31

Since the number n
has exactly ⌊log2n⌋+1 digits in base 2, we only need to perform O(logn) multiplications, if we know the powers a1,a2,a4,a8,…,a⌊logn⌋

.

So we only need to know a fast way to compute those. Luckily this is very easy, since an element in the sequence is just the square of the previous element.
31323438=3=(31)2=32=9=(32)2=92=81=(34)2=812=6561

So to get the final answer for 313
, we only need to multiply three of them (skipping 32 because the corresponding bit in n is not set): 313=6561⋅81⋅3=1594323

The final complexity of this algorithm is O(logn)
: we have to compute logn powers of a, and then have to do at most logn

multiplications to get the final answer from them.

The following recursive approach expresses the same idea:
an=⎧⎩⎨⎪⎪⎪⎪⎪⎪⎪⎪1(an2)2(an−12)2⋅aif n==0if n>0 and n evenif n>0 and n odd
Implementation

First the recursive approach, which is a direct translation of the recursive formula:

long long binpow(long long a, long long b) {
    if (b == 0)
        return 1;
    long long res = binpow(a, b / 2);
    if (b % 2)
        return res * res * a;
    else
        return res * res;
}

The second approach accomplishes the same task without recursion. It computes all the powers in a loop, and multiplies the ones with the corresponding set bit in n

. Although the complexity of both approaches is identical, this approach will be faster in practice since we don't have the overhead of the recursive calls.

long long binpow(long long a, long long b) {
    long long res = 1;
    while (b > 0) {
        if (b & 1)
            res = res * a;
        a = a * a;
        b >>= 1;
    }
    return res;
}

Applications
Effective computation of large exponents modulo a number

Problem: Compute xnmodm

. This is a very common operation. For instance it is used in computing the modular multiplicative inverse.

Solution: Since we know that the module operator doesn't interfere with multiplications (a⋅b≡(amodm)⋅(bmodm)(modm)

), we can directly use the same code, and just replace every multiplication with a modular multiplication:

long long binpow(long long a, long long b, long long m) {
    a %= m;
    long long res = 1;
    while (b > 0) {
        if (b & 1)
            res = res * a % m;
        a = a * a % m;
        b >>= 1;
    }
    return res;
}

Note: If m
is a prime number we can speed up a bit this algorithm by calculating xnmod(m−1) instead of xn

. This follows directly from Fermat's little theorem.
Effective computation of Fibonacci numbers

Problem: Compute n
-th Fibonacci number Fn

.

Solution: For more details, see the Fibonacci Number article. We will only go through an overview of the algorithm. To compute the next Fibonacci number, only the two previous ones are needed, as Fn=Fn−1+Fn−2
. We can build a 2×2 matrix that describes this transformation: the transition from Fi and Fi+1 to Fi+1 and Fi+2. For example, applying this transformation to the pair F0 and F1 would change it into F1 and F2. Therefore, we can raise this transformation matrix to the n-th power to find Fn in time complexity O(logn)

.
Applying a permutation k
times

Problem: You are given a sequence of length n
. Apply to it a given permutation k

times.

Solution: Simply raise the permutation to k
-th power using binary exponentiation, and then apply it to the sequence. This will give you a time complexity of O(nlogk)

.

Note: This task can be solved more efficiently in linear time by building the permutation graph and considering each cycle independently. You could then compute k

modulo the size of the cycle and find the final position for each number which is part of this cycle.
Fast application of a set of geometric operations to a set of points

Problem: Given n
points pi, apply m transformations to each of these points. Each transformation can be a shift, a scaling or a rotation around a given axis by a given angle. There is also a "loop" operation which applies a given list of transformations k times ("loop" operations can be nested). You should apply all transformations faster than O(n⋅length), where length

is the total number of transformations to be applied (after unrolling "loop" operations).

Solution: Let's look at how the different types of transformations change the coordinates:

    Shift operation: adds a different constant to each of the coordinates.
    Scaling operation: multiplies each of the coordinates by a different constant.
    Rotation operation: the transformation is more complicated (we won't go in details here), but each of the new coordinates still can be represented as a linear combination of the old ones.

As you can see, each of the transformations can be represented as a linear operation on the coordinates. Thus, a transformation can be written as a 4×4

matrix of the form:
⎛⎝⎜⎜⎜⎜⎜⎜a11 a21 a31 a41 a12a22a32a42a13a23a33a43a14a24a34a44⎞⎠⎟⎟⎟⎟⎟⎟

that, when multiplied by a vector with the old coordinates and an unit gives a new vector with the new coordinates and an unit:
(xyz1)⋅⎛⎝⎜⎜⎜⎜⎜⎜a11 a21 a31 a41 a12a22a32a42a13a23a33a43a14a24a34a44⎞⎠⎟⎟⎟⎟⎟⎟=(x′y′z′1)

(Why introduce a fictitious fourth coordinate, you ask? Without this, it would not be possible to implement the shift operation, as it requires us to add a constant to the coordinates. Without the fictitious coordinates, we would only be able to apply a linear combination to the coordinates, not being able to add a constant.)

Here are some examples of how transformations are represented in matrix form:

    Shift operation: shift x

coordinate by 5, y coordinate by 7 and z coordinate by 9

    .

⎛⎝⎜⎜⎜⎜⎜⎜1 0 0 5 010700190001⎞⎠⎟⎟⎟⎟⎟⎟

    Scaling operation: scale the x

coordinate by 10 and the other two by 5

    .

⎛⎝⎜⎜⎜⎜⎜⎜10 0 0 0 050000500001⎞⎠⎟⎟⎟⎟⎟⎟

    Rotation operation: rotate θ

degrees around the x

    axis following the right-hand rule (counter-clockwise direction).

⎛⎝⎜⎜⎜⎜⎜⎜1 0 0 0 0cosθsinθ00−sinθcosθ00001⎞⎠⎟⎟⎟⎟⎟⎟

Now, once every transformation is described as a matrix, the sequence of transformations can be described as a product of these matrices, and a "loop" of k
repetitions can be described as the matrix raised to the power of k (which can be calculated using binary exponentiation in O(logk)). This way, the matrix which represents all transformations can be calculated first in O(mlogk), and then it can be applied to each of the n points in O(n) for a total complexity of O(n+mlogk)

.
Number of paths of length k
in a graph

Problem: Given a directed unweighted graph of n
vertices, find the number of paths of length k from any vertex u to any other vertex v

.

Solution: This problem is considered in more detail in a separate article. The algorithm consists of raising the adjacency matrix M
of the graph (a matrix where mij=1 if there is an edge from i to j, or 0 otherwise) to the k-th power. Now mij will be the number of paths of length k from i to j. The time complexity of this solution is O(n3logk)

.

Note: In that same article, another variation of this problem is considered: when the edges are weighted and it is required to find the minimum weight path containing exactly k
edges. As shown in that article, this problem is also solved by exponentiation of the adjacency matrix. The matrix would have the weight of the edge from i to j, or ∞ if there is no such edge. Instead of the usual operation of multiplying two matrices, a modified one should be used: instead of multiplication, both values are added, and instead of a summation, a minimum is taken. That is: resultij=min1 ≤ k ≤ n(aik+bkj)

.
Variation of binary exponentiation: multiplying two numbers modulo m

Problem: Multiply two numbers a
and b modulo m. a and b fit in the built-in data types, but their product is too big to fit in a 64-bit integer. The idea is to compute a⋅b(modm)

without using bignum arithmetics.

Solution: We simply apply the binary construction algorithm described above, only performing additions instead of multiplications. In other words, we have "expanded" the multiplication of two numbers to O(logm)

operations of addition and multiplication by two (which, in essence, is an addition).
a⋅b=⎧⎩⎨⎪⎪02⋅a2⋅b2⋅a−12⋅b+bif a=0if a>0 and a evenif a>0 and a odd

Note: You can solve this task in a different way by using floating-point operations. First compute the expression a⋅bm
using floating-point numbers and cast it to an unsigned integer q. Subtract q⋅m from a⋅b using unsigned integer arithmetics and take it modulo m to find the answer. This solution looks rather unreliable, but it is very fast, and very easy to implement.
